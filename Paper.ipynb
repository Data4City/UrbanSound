{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from librosa import display\n",
    "import librosa\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming a panda dataframe from the metadata file\n",
    "data=pd.read_csv(\"UrbanSound8K/metadata/UrbanSound8K.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 8732/8732 [17:04<00:00, 10.09it/s]\n"
     ]
    }
   ],
   "source": [
    "#preprocessing using only mfcc\n",
    "x_train=[]\n",
    "x_test=[]\n",
    "y_train=[]\n",
    "y_test=[]\n",
    "path=\"UrbanSound8K/audio/fold\"\n",
    "for i in tqdm(range(len(data))):\n",
    "    fold_no=str(data.iloc[i][\"fold\"])\n",
    "    file=data.iloc[i][\"slice_file_name\"]\n",
    "    label=data.iloc[i][\"classID\"]\n",
    "    filename=path+fold_no+\"/\"+file\n",
    "    #print(filename)\n",
    "    y,sr=librosa.load(filename)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y, sr, n_mfcc=40).T,axis=0)\n",
    "    #print(mfccs.shape,mfccs.max(),mfccs.min())\n",
    "    if(fold_no!='10'):\n",
    "      x_train.append(mfccs)\n",
    "      y_train.append(label)\n",
    "    else:\n",
    "      x_test.append(mfccs)\n",
    "      y_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/8732 [00:00<?, ?it/s]c:\\users\\anton\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\scipy\\sparse\\lil.py:506: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n",
      "  1%|▌                                                                               | 67/8732 [00:19<43:40,  3.31it/s]c:\\users\\anton\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\librosa\\core\\pitch.py:146: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 8732/8732 [40:38<00:00,  4.27it/s]\n"
     ]
    }
   ],
   "source": [
    "#preprocessing using entire feature set\n",
    "x_train=[]\n",
    "x_test=[]\n",
    "y_train=[]\n",
    "y_test=[]\n",
    "path=\"UrbanSound8K/audio/fold\"\n",
    "for i in tqdm(range(len(data))):\n",
    "    fold_no=str(data.iloc[i][\"fold\"])\n",
    "    file=data.iloc[i][\"slice_file_name\"]\n",
    "    label=data.iloc[i][\"classID\"]\n",
    "    filename=path+fold_no+\"/\"+file\n",
    "    y,sr=librosa.load(filename)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y, sr, n_mfcc=40).T,axis=0)\n",
    "    melspectrogram = np.mean(librosa.feature.melspectrogram(y=y, sr=sr, n_mels=40,fmax=8000).T,axis=0)\n",
    "    chroma_stft=np.mean(librosa.feature.chroma_stft(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    chroma_cq = np.mean(librosa.feature.chroma_cqt(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    chroma_cens = np.mean(librosa.feature.chroma_cens(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    features=np.reshape(np.vstack((mfccs,melspectrogram,chroma_stft,chroma_cq,chroma_cens)),(40,5))\n",
    "    if(fold_no!='10'):\n",
    "      x_train.append(features)\n",
    "      y_train.append(label)\n",
    "    else:\n",
    "      x_test.append(features)\n",
    "      y_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7895, 40, 5), (837, 40, 5), (7895,), (837,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#converting the lists into numpy arrays\n",
    "x_train=np.array(x_train)\n",
    "x_test=np.array(x_test)\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7895, 200), (837, 200))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshaping into 2d to save in csv format\n",
    "x_train_2d=np.reshape(x_train,(x_train.shape[0],x_train.shape[1]*x_train.shape[2]))\n",
    "x_test_2d=np.reshape(x_test,(x_test.shape[0],x_test.shape[1]*x_test.shape[2]))\n",
    "x_train_2d.shape,x_test_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#saving the data numpy arrays\n",
    "np.savetxt(\"train_data.csv\", x_train_2d, delimiter=\",\")\n",
    "np.savetxt(\"test_data.csv\",x_test_2d,delimiter=\",\")\n",
    "np.savetxt(\"train_labels.csv\",y_train,delimiter=\",\")\n",
    "np.savetxt(\"test_labels.csv\",y_test,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\anton\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\anton\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\anton\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\anton\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\anton\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\anton\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((7895, 10), (837, 10))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting to one hot\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7895, 40, 5), (837, 40, 5))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshaping to 2D \n",
    "x_train=np.reshape(x_train,(x_train.shape[0], 40,5))\n",
    "x_test=np.reshape(x_test,(x_test.shape[0], 40,5))\n",
    "x_train.shape,x_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#reshaping to shape required by CNN\n",
    "x_train=np.reshape(x_train,(x_train.shape[0], 40,5,1))\n",
    "x_test=np.reshape(x_test,(x_test.shape[0], 40,5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping,TensorBoard\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding layers and forming the model\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,kernel_size=5,strides=1,padding=\"Same\",activation=\"relu\",input_shape=(40,5,1)))\n",
    "    model.add(MaxPooling2D(padding=\"same\"))\n",
    "    \n",
    "    model.add(Conv2D(64,kernel_size=5,strides=1,padding=\"same\",activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(padding=\"same\"))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(128,kernel_size=5,strides=1,padding=\"same\",activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(padding=\"same\"))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128,activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(128,activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(10,activation=\"softmax\"))\n",
    "    return model\n",
    "def get_callbacks(name_weights, patience_lr):\n",
    "     \n",
    "    mcp_save = ModelCheckpoint(\"weights/{}_weights.h5\".format(name_weights), save_best_only=True, monitor='val_loss', mode='min')\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=patience_lr, verbose=1, epsilon=1e-4, mode='auto')\n",
    "    tensorboard = TensorBoard(log_dir='logs/{}'.format(name_weights))\n",
    "    es = EarlyStopping(monitor='val_acc', mode='max', min_delta=1, patience=30, verbose=1)\n",
    "    return [mcp_save, reduce_lr_loss, tensorboard, es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00031: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1812ea74f60>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_check= \"paper_more_conv_less_dense_128_second\"\n",
    "model = get_model()\n",
    "\n",
    "callbacks = get_callbacks(name_check, patience_lr=10)\n",
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.fit(x_train,y_train,batch_size=50,epochs=150,validation_data=(x_test,y_test),callbacks = callbacks,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_path = serving\\paper_more_conv_less_dense_128_second\\1\n",
      "\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'serving\\\\paper_more_conv_less_dense_128_second\\\\1\\\\saved_model.pb'\n",
      "\n",
      "Saved model:\n",
      "serving\\paper_more_conv_less_dense_128_second\\1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os.path as p\n",
    "MODEL_DIR = p.join(\"serving\", name_check)\n",
    "version = 1\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "print('export_path = {}\\n'.format(export_path))\n",
    "if os.path.isdir(export_path):\n",
    "  print('\\nAlready saved a model, cleaning up\\n')\n",
    "  !rm -r {export_path}\n",
    "\n",
    "tf.saved_model.simple_save(\n",
    "    keras.backend.get_session(),\n",
    "    export_path,\n",
    "    inputs={'input_image': model.input},\n",
    "    outputs={t.name:t for t in model.outputs})\n",
    "\n",
    "print('\\nSaved model:')\n",
    "print(export_path)\n",
    "!ls -l {export_path}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
